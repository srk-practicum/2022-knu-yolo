{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af4b9b8a",
   "metadata": {},
   "source": [
    "# Train NN model on the FashionMNIST data\n",
    "\n",
    "https://www.kaggle.com/zalando-research/fashionmnist\n",
    "\n",
    "Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n",
    "\n",
    "You may refer to this tutorial about the original Mnist:\n",
    "https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627\n",
    "\n",
    "Or any other tutorial you may find online:\n",
    "https://www.kaggle.com/zalando-research/fashionmnist/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a60fad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33c19eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "605d1835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lest read a random image from the dataset and draw it\n",
    "image, label = training_data[17]\n",
    "plt.imshow(image[0], \"gray\")\n",
    "plt.title(f\"Image of class: {label}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f490ddd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check image shape\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16f15225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets see all the classes available\n",
    "training_data.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2a7f78",
   "metadata": {},
   "source": [
    "# Task 1:\n",
    "\n",
    "Create a DataLoader objects for train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97c9881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0695343f",
   "metadata": {},
   "source": [
    "# Task 2:\n",
    "\n",
    "Create a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9b3d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "  def __init__(self):\n",
    "        super().__init__()\n",
    "        self.normalize = nn.functional.normalize\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "        self.relu = nn.functional.relu\n",
    "        self.softmax = nn.functional.softmax\n",
    "  def forward(self, x):\n",
    "    x = x.reshape(-1, 784)\n",
    "    x = self.relu(self.fc1(x))\n",
    "    x = self.relu(self.fc2(x))\n",
    "    # x = self.relu(self.fc3(x))\n",
    "    x = self.softmax(self.fc4(x), dim=1)\n",
    "    return x\n",
    "\n",
    "\n",
    "model = Network()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13d5117",
   "metadata": {},
   "source": [
    "# Task 3:\n",
    "\n",
    "Specify loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cd11bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "#device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605caa5b",
   "metadata": {},
   "source": [
    "# Task 3:\n",
    "\n",
    "Train model using for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a724b721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed epoch 1\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "  for batch, (X, y) in enumerate(dataloader):\n",
    "      pred = model.forward(X)\n",
    "      loss = loss_fn(pred, y)\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "  if epoch % 10 == 0:\n",
    "    print(f\"Passed epoch {epoch + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d61b00",
   "metadata": {},
   "source": [
    "# Task 4:\n",
    "\n",
    "Report accuracy from train set, and test set independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d129cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "826ea8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader):\n",
    "  all_preds = torch.tensor([])\n",
    "  true_vals = torch.tensor([])\n",
    "  with torch.no_grad():\n",
    "    for (X, y) in dataloader:\n",
    "      all_preds = torch.cat((all_preds, model.forward(X)), 0)\n",
    "      true_vals = torch.cat((true_vals, y), 0)\n",
    "  return all_preds, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1910973",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train, vals_train = predict(model, dataloader)\n",
    "preds_test, vals_test = predict(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e99d60bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on a train set:\n",
      "tensor(0.8787)\n",
      "Accuracy on a test set\n",
      "tensor(0.8586)\n"
     ]
    }
   ],
   "source": [
    "acc_train = accuracy(preds_train, vals_train)\n",
    "acc_test = accuracy(preds_test, vals_test)\n",
    "print(\"Accuracy on a train set:\")\n",
    "print(acc_train)\n",
    "print(\"Accuracy on a test set\")\n",
    "print(acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfcc3eb",
   "metadata": {},
   "source": [
    "# Task 5:\n",
    "\n",
    "Report confussion matrix for the test set\n",
    "\n",
    "Expected format:\n",
    "```\n",
    "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1beb09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[803  12  15  61   3   0  94   0  12   0]\n",
      " [  2 974   0  20   1   0   2   0   1   0]\n",
      " [  9  20 807  23  94   0  41   0   5   1]\n",
      " [ 15  23   5 918  14   1  18   0   6   0]\n",
      " [  0  14 135  77 715   0  51   0   8   0]\n",
      " [  0   0   0   1   0 919   0  41   2  37]\n",
      " [124  12 114  56  77   0 600   0  17   0]\n",
      " [  0   0   0   0   0  13   0 965   0  22]\n",
      " [  0  14   1   6   1   2   4   4 968   0]\n",
      " [  0   1   0   0   0   3   1  78   0 917]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "_, preds = torch.max(preds_test, dim=1)\n",
    "conf_mat = confusion_matrix(vals_test.numpy(), preds.numpy())\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2a7f90",
   "metadata": {},
   "source": [
    "# Task 6 (optional):\n",
    "\n",
    "Train LogisticRegression and DecisionTree models on the same data\n",
    "Compare their performance to the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f009b458",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "     def __init__(self, input_dim, output_dim):\n",
    "      super(LogisticRegression, self).__init__()\n",
    "      self.linear = nn.Linear(input_dim, output_dim)\n",
    "     def forward(self, x):\n",
    "      x = x.reshape(-1, 784)\n",
    "      outputs = torch.sigmoid(self.linear(x))\n",
    "      return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b256a0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed epoch 0\n",
      "Passed epoch 1\n",
      "Passed epoch 2\n",
      "Passed epoch 3\n",
      "Passed epoch 4\n",
      "Passed epoch 5\n",
      "Passed epoch 6\n",
      "Passed epoch 7\n",
      "Passed epoch 8\n",
      "Passed epoch 9\n"
     ]
    }
   ],
   "source": [
    "log_regression = LogisticRegression(784, 10)\n",
    "\n",
    "for epoch in range(10):\n",
    "  for batch, (X, y) in enumerate(dataloader):\n",
    "      #X, y = X.to(device), y.to(device)\n",
    "      \n",
    "      pred = log_regression.forward(X)\n",
    "      loss = loss_fn(pred, y)\n",
    "      \n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "  print(f\"Passed epoch {epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f3c380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds, _ = predict(log_regression, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0591d1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression 0.10670000314712524\n"
     ]
    }
   ],
   "source": [
    "log_acc = accuracy(log_preds, vals_test)\n",
    "print(f\"Accuracy of logistic regression {log_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05820764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "train_loader = DataLoader(training_data, batch_size=len(training_data))\n",
    "train_dataset_array = training_data.data.numpy()\n",
    "train_dataset_array = train_dataset_array.reshape(-1, 784)\n",
    "training_dataset_labels = training_data.targets.numpy()\n",
    "test_dataset_array = test_data.data.numpy()\n",
    "test_dataset_array = test_dataset_array.reshape(-1, 784)\n",
    "test_dataset_labels = test_data.targets.numpy()\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(train_dataset_array, training_dataset_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1edb6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 6 1 ... 8 1 5]\n"
     ]
    }
   ],
   "source": [
    "tree_preds = tree.predict(test_dataset_array)\n",
    "\n",
    "print(tree_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "abfb35cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.792\n"
     ]
    }
   ],
   "source": [
    "tree_acc = (tree_preds == test_dataset_labels).sum() / len(tree_preds)\n",
    "print(tree_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
